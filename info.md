Generative AI Engineer 1, 2
Длительность курса в неделях 26
Продолжительность курса в
академических часах
104
Описание курса Этот комплексный курс проведет вас от основ генеративного ИИ до
создания и развертывания сложных ИИ-агентов. Вы освоите
большие языковые модели, такие как GPT и Llama, изучите
продвинутый промпт-инжиниринг и научитесь создавать мощные
RAG-системы с использованием векторных баз данных.
Значительная часть курса посвящена разработке автономных
агентов с помощью фреймворков LangChain и CrewAI. Через
еженедельные практические проекты вы также изучите дообучение
моделей (LoRA), создание производственных API на FastAPI,
контейнеризацию с Docker и развертывание приложений в облаке.
По окончании курса вы будете обладать навыками для создания
полноценных, реальных ИИ-решений.
Цели Обучить студентов проектированию, созданию и развертыванию
реальных приложений на основе генеративного ИИ: от RAG-систем
и автономных агентов до готовых к продакшену облачных сервисов.
Формат обучения Online
Периодичность занятий
Преподаватели:
Леонид Гельвих
Сооснователь AI automation agency, Cognitive Architect, Lead AI PM,
преподаватель с опытом работы с более чем 1000 студентов, автор MCP‑Buildeh читает Core‑лекции,
проводит AMA и Demo Day, утверждает задания.
Приглашенные спикеры
Дарья Соколова
AI‑Engineer, Google Developer Expert (GenAI)
Павел Дмитриев
Data Scientist, ex‑Microsoft (metrics & evaluation)
Ник Макфлай
СЕО Hybrain Ltd., AI-эксперт
Руслан Сыздыков
промпт-инженер Higgsfield AI
Медет Турин
эксперт кибербезопасности, №1 белый хакер РК
Максат Бекес
AI-эксперт, разработчик
Ник Широбоков
кофаундер, AI инженер и биздев @TensorSense
Таалай Джумабаев
фаундер Growthhungry Academy, экс @google
Generative AI Engineer 1
Лекция 1 Введение в Генеративный ИИ
и большие языковые модели
(LLM)
Экосистема LLM с открытым
исходным кодом
На этой неделе рассматриваются фундаментальные
концепции генеративного ИИ. Мы изучим историю и
архитектуру LLM, сравним основные модели, такие как
GPT, Gemini, Claude и Grok. Вы поймете, что делает эти
модели мощными, и каковы их основные возможности.
Погрузитесь в мир моделей с открытым исходным кодом.
Мы изучим ведущие модели, такие как Llama, Mistral,
Qwen и DeepSeek. Вы научитесь использовать
HuggingFace Hub для поиска, оценки и применения
предварительно обученных моделей.
Проект 1 Студенты используют API или веб-интерфейсы
нескольких ведущих LLM (например, GPT, Gemini,
Claude) для решения стандартизированного набора задач
(резюмирование, креативное письмо, логические задачи).
Цель — подготовить отчет, сравнивающий
производительность, стиль и сильные стороны каждой
модели.
Студенты выбирают модель с открытым исходным кодом
(например, Llama, Mistral) с HuggingFace и оценивают ее
эффективность на специфической задаче по своему
выбору (например, генерация документации к коду,
создание маркетинговых текстов, написание игровых
диалогов).
Лекция 2 Запуск LLM локально с
помощью Ollama
Узнайте, как настраивать и запускать мощные LLM на
вашем собственном компьютере. Эта неделя посвящена
Ollama для интеграции локальных моделей. Мы обсудим
преимущества локального выполнения для
конфиденциальности, стоимости и кастомизации. Также
мы затронем создание REST API для вашей локальной
модели.
Проект 2 Студенты настраивают Ollama, загружают модель и
создают простой REST API (например, на FastAPI),
который предоставляет доступ к возможностям локальной
модели. Задача — написать клиентское приложение для
взаимодействия с этим API.
Лекция 3 Основы разработки
приложений на базе LLM
Прежде чем приступить к созданию, мы рассмотрим
основы управления LLM-приложениями. Темы включают
реализацию стриминга ответов для улучшения
пользовательского опыта, базовое логирование, стратегии
отслеживания затрат и определение ключевых метрик
производительности.
Проект 3 Студенты разрабатывают базовое веб-приложение,
которое взаимодействует с API LLM и отображает ответ
токен за токеном (в режиме стриминга). Также
Лекция 4 Проект 4 Лекция 5 Проект 5 Лекция 6 Проект 6 Основы промпт-инжиниринга
Продвинутые техники
промпт-инжиниринга
Введение в LangChain Основы Retrieval-Augmented
Generation (RAG)
необходимо реализовать базовое логирование пар
«запрос-ответ».
Освойте искусство общения с LLM. На этой неделе
рассматриваются базовые техники, такие как zero-shot,
one-shot и few-shot промптинг (без примеров, с одним и
несколькими примерами), а также важность четких
инструкций, ролей и форматирования.
Выйдите за рамки основ, чтобы получать от LLM более
сложные рассуждения. Мы изучим продвинутые
стратегии, такие как Chain-of-Thought (цепочка мыслей),
Self-Consistency (самосогласованность) и Tree of Thoughts
(дерево мыслей), чтобы повысить точность и надежность
ответов модели.
Студенты используют few-shot промптинг, чтобы
заставить LLM общего назначения работать как
классификатор текста в определенной области (например,
анализ тональности, классификация тем) без какого-либо
дообучения. Проект включает эксперименты с разными
примерами и стилями инструкций.
Студенты выбирают набор логических головоломок или
многошаговых задач и разрабатывают промпт в стиле
Chain-of-Thought, чтобы направить LLM к пошаговому
решению. Результаты сравниваются с результатами,
полученными без этой техники.
Узнайте, как эффективно создавать приложения на базе
LLM с помощью фреймворка LangChain. Мы рассмотрим
его основные компоненты для создания цепочек
промптов, управления памятью и структурирования
взаимодействий с LLM.
Студенты используют LangChain для создания
приложения, которое объединяет несколько вызовов LLM
в цепочку. Например, цепочка, которая сначала
генерирует идею для темы, затем пишет короткий пост в
блог, и, наконец, создает пост для социальных сетей для
его продвижения.
Узнайте, как «заземлить» LLM на ваших собственных
данных. На этой неделе вводится ключевая концепция
RAG, объясняется, почему она важна для уменьшения
галлюцинаций и создания контекстно-зависимых
приложений. Мы рассмотрим базовую архитектуру:
загрузка, разделение, векторизация, хранение и
извлечение.
Студенты создают базовую RAG-систему, которая может
Лекция 7 Проект 7 Лекция 8 Проект 8 Лекция 9 Проект 9 Лекция 10 Подготовка данных и чанкинг
(разделение на части)
Введение в векторные базы
данных
Реализация RAG с помощью
pgvector и Supabase
Продвинутый поиск с Hybrid
Search и RRF
отвечать на вопросы по одному текстовому документу
(например, PDF научной статьи). Необходимо реализовать
базовый пайплайн: загрузка, разделение, векторизация и
извлечение.
Эффективный RAG начинается с правильной обработки
данных. Мы сосредоточимся на продвинутых стратегиях
чанкинга для разделения документов, обсуждая
компромиссы между различными размерами фрагментов,
их пересечениями и методами.
Студенты берут сложный документ (например, длинный
отчет с таблицами) и применяют к нему различные
стратегии чанкинга (фиксированный размер,
рекурсивный, семантический). Цель — проанализировать
качество полученных фрагментов и сохранение контекста.
Изучите специализированные базы данных для хранения
и запроса векторных представлений (эмбеддингов). Мы
сравним возможности и сценарии использования
популярных решений, таких как Pinecone, Qdrant и
расширения с открытым исходным кодом pgvector для
PostgreSQL.
Студенты выбирают векторную базу данных (Pinecone,
Qdrant и т.д.), векторизуют небольшой набор текстовых
документов и загружают их в базу. Затем они реализуют
функцию семантического поиска для извлечения
наиболее релевантных документов.
Получите практический опыт создания RAG-пайплайна.
Эта неделя представляет собой практическое руководство
по использованию pgvector в проекте на Supabase: от
настройки базы данных до реализации полного цикла
извлечения и генерации.
Студенты создают полнофункциональное
RAG-приложение, используя Supabase для бэкенда и
pgvector для хранения векторов. Приложение должно
позволять пользователю загружать документ и
«общаться» с ним.
Повысьте точность извлечения, комбинируя различные
методы поиска. Мы рассмотрим гибридный поиск
(сочетание поиска по ключевым словам и семантического
поиска) и Reciprocal Rank Fusion (RRF) для объединения
и пересортировки результатов из нескольких источников.
Проект 10 Лекция 11 Проект 11 Лекция 12 Проект 12 Лекция 13 Проект 13 Оптимизация
производительности RAG
Введение в ИИ-агентов Фреймворк ReAct Студенты дорабатывают свой RAG-проект, реализуя
систему гибридного поиска. Они комбинируют
традиционный поиск по ключевым словам с
семантическим поиском и используют технику слияния
(например, RRF) для объединения результатов.
Настройте вашу RAG-систему для использования в
продакшене. Эта неделя посвящена переранжированию
извлеченных документов по релевантности, реализации
кеширования для ускорения ответов и использованию
A/B-тестирования для оценки различных стратегий RAG.
Студенты добавляют в свое RAG-приложение две
функции: шаг переранжирования (re-ranking) для
улучшения порядка извлеченных документов и простой
слой кеширования для хранения результатов часто
задаваемых вопросов.
Поймите переход от простых вызовов LLM к автономным
агентам. Мы дадим определение ИИ-агента, его основных
компонентов (планирование, память, инструменты) и
сравним агентов с паттернами рабочих процессов.
Студенты выбирают сложную задачу (например,
планирование поездки) и создают два проекта решения:
один в виде жесткого, предопределенного рабочего
процесса (workflow) и другой в виде автономного агента с
инструментами. Необходимо документировать плюсы и
минусы каждого подхода.
Создайте своего первого агента, используя
промптинг-фреймворк ReAct (Reason and Act – Рассуждай
и Действуй). Вы научитесь инструктировать LLM «думать
вслух» и решать, какие инструменты использовать для
выполнения задачи.
Студенты создают агента, который может использовать
несколько простых инструментов (например, калькулятор,
функция текущей даты) с помощью промптинга в стиле
ReAct. Цель — научить агента решать задачи, требующие
использования инструментов.
Generative AI Engineer 2
Лекция 1 Создание агентов с помощью
LangGraph
Проект 1 Лекция 2 Мультиагентные системы с
AutoGen
Проект 2 Лекция 3 Совместная работа агентов с
CrewAI
Проект 3 Лекция 4 Интеграция инструментов:
внешние API и веб-скрапинг
Проект 4 Перейдите от линейных цепочек к циклическим графам с
помощью LangGraph. На этой неделе мы научимся
создавать надежные, циклические агентные системы, в
которых LLM может повторять действия,
самокорректироваться и рассуждать в несколько этапов,
что идеально подходит для сложных задач.
Используя LangGraph, студенты создают агента, который
может критиковать собственный результат и итеративно
его улучшать. Например, агент, который пишет абзац,
затем вызывает узел «критика» для его проверки и
переходит в узел «редактирования» на основе полученной
обратной связи.
Узнайте, как заставить специализированных агентов
работать вместе. Мы будем использовать фреймворк
AutoGen от Microsoft для создания диалогов между
несколькими агентами, у каждого из которых своя роль,
для совместного решения сложных проблем.
Студенты используют AutoGen для настройки диалоговой
системы с несколькими агентами, имеющими разные
роли (например, техно-оптимист, скептик, финансовый
аналитик). Группе дается тема для обсуждения, и проект
заключается в организации структурированных дебатов.
Изучите еще один мощный фреймворк для оркестровки
мультиагентных систем. CrewAI фокусируется на ролевом
дизайне агентов, позволяя вам определить «команду»
агентов с конкретными задачами и процессом для
достижения общей цели.
Используя CrewAI, студенты определяют команду агентов
с конкретными ролями (например,
«Аналитик-исследователь», «Писатель», «Редактор») для
автоматизации процесса создания контента. Цель — дать
команде тему, после чего она должна автономно создать
готовую статью.
Сила агента заключается в его инструментах. Эта неделя
посвящена практическим навыкам интеграции внешних
API и веб-скрапинга, что позволит вашим агентам
взаимодействовать с цифровым миром и получать доступ
к информации в реальном времени.
Студенты создают агента и оснащают его двумя
реальными инструментами путем интеграции внешних
Лекция 5 Проект 5 Лекция 6 Проект 6 Лекция 7 Проект 7 Лекция 8 Создание агента для
углубленных исследований
Наблюдаемость и отладка с
помощью LangSmith
Изучение альтернативных
фреймворков для агентов и
рабочих процессов
Введение в дообучение
(Fine-Tuning)
Параметро-эффективное
API: один для получения погоды, другой для получения
последних новостей. Агент должен уметь отвечать на
вопросы, комбинируя информацию из обоих источников.
Примените свои навыки создания агентов в практическом
проекте. Вы спроектируете и реализуете агента для
углубленных исследований, который сможет
просматривать веб-страницы, синтезировать информацию
из нескольких источников и генерировать
исчерпывающий отчет по заданной теме.
Студенты создают исследовательского агента, который по
заданной теме (например, «Квантовые вычисления»)
автономно ищет в интернете свежие статьи, извлекает
ключевую информацию и синтезирует ее в
структурированный итоговый отчет.
Отслеживайте и отлаживайте свои сложные
LLM-приложения. Мы будем использовать LangSmith,
чтобы получить представление о поведении агента,
отслеживать цепочки «промпт-ответ» и оценивать
производительность ваших систем.
Студентам предоставляется заведомо неисправный или
неэффективный агент. Их задача — использовать
LangSmith для отслеживания его выполнения, выявления
первопричины проблемы (например, плохой промпт,
неправильное использование инструмента) и ее
устранения.
Расширьте свой инструментарий, изучив другие
популярные решения. На этой неделе будет представлен
обзор OpenAI Agents SDK и инструментов визуальной
автоматизации рабочих процессов, таких как n8n, с
сравнением их сильных сторон и идеальных сценариев
использования.
Студенты воспроизводят простую агентную задачу
(например, получение данных из API и отправка
отформатированного электронного письма) с помощью
визуального конструктора рабочих процессов, такого как
n8n. Затем они пишут краткое сравнение визуального
подхода с подходом "code-first" фреймворков.
Узнайте, когда и как кастомизировать базовую LLM. Мы
рассмотрим разницу между промптингом, RAG и
дообучением, а также обсудим сценарии, в которых
Проект 8 Лекция 9 Проект 9 Лекция 10 Проект 10 дообучение (PEFT) Создание производственного
API с помощью FastAPI
Контейнеризация с помощью
Docker
CI/CD и облачное
развертывание
дообучение является наиболее эффективным подходом.
Откройте для себя современные техники эффективной
адаптации моделей. Эта неделя посвящена LoRA и
QLoRA — методам, которые позволяют дообучать
большие модели со значительно меньшими
вычислительными ресурсами по сравнению с полным
дообучением.
Проект посвящен самому важному шагу дообучения —
данным. Студенты выбирают задачу (например,
генерация SQL-запросов из естественного языка) и
создают качественный, отформатированный набор
данных из не менее 100 пар «промпт-ответ».
Студенты берут набор данных с предыдущей недели и
используют библиотеку, такую как TRL от HuggingFace,
для дообучения небольшой open-source модели с
помощью QLoRA. Затем они тестируют
производительность дообученной модели и сравнивают ее
с базовой.
Упакуйте ваше ИИ-приложение в надежный и
масштабируемый API. Мы будем использовать FastAPI
для создания высокопроизводительного бэкенда,
определяя эндпоинты для взаимодействия с
пользователем и управления асинхронными задачами.
Студенты создают приложение на FastAPI, которое
обслуживает их дообученную модель с предыдущей
недели. API должен иметь как минимум один эндпоинт,
который принимает промпт и возвращает
сгенерированный моделью ответ.
Упакуйте ваше приложение для простого развертывания.
На этой неделе рассматриваются основы Docker: вы
научитесь создавать контейнер для вашего
FastAPI-приложения и всех его зависимостей,
обеспечивая его стабильную работу в любой среде.
Автоматизируйте процесс развертывания. Мы настроим
пайплайн CI/CD (непрерывная интеграция/непрерывное
развертывание) и развернем наше контейнеризованное
приложение на современных облачных платформах, таких
как Railway и Vercel.
Студенты пишут Dockerfile для своего
FastAPI-приложения. Цель — создать самодостаточный
Docker-образ, который включает приложение, веса
дообученной модели и все необходимые зависимости.
Студенты настраивают CI/CD пайплайн (например, с
помощью GitHub Actions) для автоматической сборки
Docker-образа и его развертывания на облачной
платформе (например, Railway) при каждом изменении в
Лекция 11 Проект 11 Лекция 12 Проект 12 Лекция 13 Проект 13 Безопасность в продакшене и
лучшие практики
Создание пользовательского
интерфейса с помощью
React/Next.js
Итоговый проект основной ветке репозитория.
Обезопасьте ваше производственное приложение. Эта
неделя посвящена основным мерам безопасности,
включая защиту от инъекций в промпты, внедрение
ограничения частоты запросов (rate limiting) и серверную
валидацию входных данных. Мы также обсудим
развивающийся Model Context Protocol.
Студенты добавляют функции безопасности и
надежности в свое развернутое API. Это включает в себя
реализацию ограничителя частоты запросов (rate limiter)
для предотвращения злоупотреблений и добавление
надежной валидации входных данных.
Создайте фронтенд для вашего ИИ-приложения. Вы
изучите основы создания интерактивного
пользовательского интерфейса с использованием React и
Next.js, что позволит реализовать такие функции, как
история чата и стриминг ответов.
Студенты создают минималистичный фронтенд с
использованием React или Next.js, который
взаимодействует с их развернутым бэкендом на FastAPI.
Интерфейс должен иметь поле ввода для промпта
пользователя и область для отображения ответа модели.
Объедините все полученные знания в итоговом проекте.
Студенты должны будут спроектировать, создать и
развернуть полноценное end-to-end приложение на базе
генеративного ИИ.
Студенты проектируют и создают с нуля комплексное
приложение, решающее реальную проблему с помощью
автономного агента или мультиагентной системы. Проект
должен включать кастомный инструмент, готовый к
продакшену API, простой пользовательский интерфейс и
быть развернут в облаке.