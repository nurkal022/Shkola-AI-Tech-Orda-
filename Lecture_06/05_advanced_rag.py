"""
–®–∞–≥ 5: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ RAG
==============================
–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ RAG: –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ, –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫, 
self-query –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏.
"""

import os
from pathlib import Path
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

load_dotenv()


class AdvancedRAG:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π RAG —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.
    """
    
    def __init__(
        self,
        model_name: str = "gpt-4.1-mini",
        embedding_model: str = "text-embedding-3-small",
        vectorstore_path: Optional[str] = None
    ):
        self.llm = ChatOpenAI(model=model_name, temperature=0.3)
        self.embeddings = OpenAIEmbeddings(model=embedding_model)
        
        self.vectorstore = None
        if vectorstore_path and Path(vectorstore_path).exists():
            self.vectorstore = FAISS.load_local(
                vectorstore_path,
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"‚úÖ Vector store –∑–∞–≥—Ä—É–∂–µ–Ω: {vectorstore_path}")
    
    # ========================================
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: Multi-Query Retrieval
    # ========================================
    def multi_query_retrieve(
        self, 
        question: str, 
        k: int = 4,
        num_queries: int = 3
    ) -> List[Document]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è.
        
        –ò–¥–µ—è: –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø–æ-—Ä–∞–∑–Ω–æ–º—É, –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        –º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ —Ä–∞–∑–Ω—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.
        """
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        query_prompt = ChatPromptTemplate.from_template(
            """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
            –î–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π {num_queries} –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö 
            —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ —Ç–æ–≥–æ –∂–µ –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
            –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏.
            
            –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {question}
            
            –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:"""
        )
        
        chain = query_prompt | self.llm | StrOutputParser()
        
        response = chain.invoke({
            "question": question,
            "num_queries": num_queries
        })
        
        # –ü–∞—Ä—Å–∏–º –∑–∞–ø—Ä–æ—Å—ã
        queries = [question]  # –í–∫–ª—é—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        queries.extend([q.strip() for q in response.strip().split('\n') if q.strip()])
        
        print(f"üîç –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤:")
        for q in queries:
            print(f"   - {q}")
        
        # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        all_docs = []
        seen_contents = set()
        
        for query in queries:
            docs = self.vectorstore.similarity_search(query, k=k)
            for doc in docs:
                content_hash = hash(doc.page_content)
                if content_hash not in seen_contents:
                    seen_contents.add(content_hash)
                    all_docs.append(doc)
        
        return all_docs[:k * 2]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    # ========================================
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: Contextual Compression
    # ========================================
    def compressed_retrieve(
        self, 
        question: str, 
        k: int = 4
    ) -> List[Document]:
        """
        –°–∂–∏–º–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–∏.
        
        –ò–¥–µ—è: –∏–∑ –±–æ–ª—å—à–æ–≥–æ —á–∞–Ω–∫–∞ –∏–∑–≤–ª–µ—á—å —Ç–æ–ª—å–∫–æ —Ç—É —á–∞—Å—Ç—å, 
        –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        """
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä
        compressor = LLMChainExtractor.from_llm(self.llm)
        
        # –°–æ–∑–¥–∞–µ–º compression retriever
        compression_retriever = ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=self.vectorstore.as_retriever(search_kwargs={"k": k})
        )
        
        docs = compression_retriever.invoke(question)
        
        print(f"üì¶ –°–∂–∞—Ç–æ –¥–æ {len(docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        return docs
    
    # ========================================
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: Reranking (–ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ)
    # ========================================
    def rerank_documents(
        self, 
        question: str,
        documents: List[Document],
        top_k: int = 4
    ) -> List[Document]:
        """
        –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM.
        
        –ò–¥–µ—è: –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Ö–æ—Ä–æ—à, –Ω–æ LLM –º–æ–∂–µ—Ç –ª—É—á—à–µ –æ—Ü–µ–Ω–∏—Ç—å
        —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É.
        """
        if not documents:
            return []
        
        rerank_prompt = ChatPromptTemplate.from_template(
            """–û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ –≤–æ–ø—Ä–æ—Å—É –ø–æ —à–∫–∞–ª–µ –æ—Ç 0 –¥–æ 10.
            –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ.
            
            –í–æ–ø—Ä–æ—Å: {question}
            
            –î–æ–∫—É–º–µ–Ω—Ç: {document}
            
            –û—Ü–µ–Ω–∫–∞ (0-10):"""
        )
        
        chain = rerank_prompt | self.llm | StrOutputParser()
        
        scored_docs = []
        for doc in documents:
            try:
                score_str = chain.invoke({
                    "question": question,
                    "document": doc.page_content[:1000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                })
                score = float(score_str.strip())
            except:
                score = 5.0  # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            
            scored_docs.append((doc, score))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        
        print(f"üìä –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        for doc, score in scored_docs[:top_k]:
            print(f"   Score {score:.1f}: {doc.metadata.get('title', 'N/A')}")
        
        return [doc for doc, _ in scored_docs[:top_k]]
    
    # ========================================
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: Parent Document Retrieval
    # ========================================
    def retrieve_with_context(
        self, 
        question: str, 
        k: int = 4,
        context_size: int = 1
    ) -> List[Document]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –æ–∫—Ä—É–∂–∞—é—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
        
        –ò–¥–µ—è: –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ —Ö–æ—Ä–æ—à–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞, –Ω–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        """
        # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
        docs = self.vectorstore.similarity_search(question, k=k)
        
        expanded_docs = []
        for doc in docs:
            chunk_id = doc.metadata.get('chunk_id', 0)
            source = doc.metadata.get('source', '')
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ—Å–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏
            expanded_content = doc.page_content
            
            # –ò—â–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫
            if chunk_id > 0:
                prev_docs = self.vectorstore.similarity_search(
                    f"chunk_id:{chunk_id - 1} source:{source}",
                    k=1
                )
                if prev_docs:
                    expanded_content = prev_docs[0].page_content + "\n\n" + expanded_content
            
            # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π —á–∞–Ω–∫
            next_docs = self.vectorstore.similarity_search(
                f"chunk_id:{chunk_id + 1} source:{source}",
                k=1
            )
            if next_docs:
                expanded_content = expanded_content + "\n\n" + next_docs[0].page_content
            
            expanded_doc = Document(
                page_content=expanded_content,
                metadata=doc.metadata
            )
            expanded_docs.append(expanded_doc)
        
        return expanded_docs
    
    # ========================================
    # –ü–æ–ª–Ω—ã–π Advanced RAG Pipeline
    # ========================================
    def advanced_query(
        self,
        question: str,
        k: int = 4,
        use_multi_query: bool = True,
        use_reranking: bool = True,
        use_compression: bool = False
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π RAG pipeline.
        """
        print(f"\n{'='*50}")
        print(f"üöÄ Advanced RAG Query")
        print(f"{'='*50}")
        print(f"‚ùì –í–æ–ø—Ä–æ—Å: {question}\n")
        
        # –®–∞–≥ 1: Retrieval
        if use_multi_query:
            print("üìç –®–∞–≥ 1: Multi-Query Retrieval")
            docs = self.multi_query_retrieve(question, k=k)
        else:
            print("üìç –®–∞–≥ 1: Standard Retrieval")
            docs = self.vectorstore.similarity_search(question, k=k*2)
        
        # –®–∞–≥ 2: Reranking
        if use_reranking:
            print("\nüìç –®–∞–≥ 2: Reranking")
            docs = self.rerank_documents(question, docs, top_k=k)
        
        # –®–∞–≥ 3: Compression (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if use_compression:
            print("\nüìç –®–∞–≥ 3: Compression")
            docs = self.compressed_retrieve(question, k=k)
        
        # –®–∞–≥ 4: Generation
        print("\nüìç –®–∞–≥ 4: Generation")
        
        context = "\n\n---\n\n".join([
            f"[{doc.metadata.get('title', 'N/A')}]\n{doc.page_content}"
            for doc in docs
        ])
        
        answer_prompt = ChatPromptTemplate.from_template(
            """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–Ω–∏–≥–∞–º –æ –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä–µ. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å,
            –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
            
            –ö–æ–Ω—Ç–µ–∫—Å—Ç:
            {context}
            
            –í–æ–ø—Ä–æ—Å: {question}
            
            –î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:"""
        )
        
        chain = answer_prompt | self.llm | StrOutputParser()
        
        answer = chain.invoke({
            "context": context,
            "question": question
        })
        
        return {
            "answer": answer,
            "num_docs_retrieved": len(docs),
            "sources": [doc.metadata.get('title') for doc in docs]
        }


def demo_advanced_rag():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ RAG"""
    print("="*60)
    print("üî¨ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø ADVANCED RAG")
    print("="*60)
    
    index_path = "./faiss_harry_potter"
    
    if not Path(index_path).exists():
        print("‚ùå –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ 04_rag_pipeline.py")
        return
    
    rag = AdvancedRAG(
        model_name="gpt-4.1-mini",
        vectorstore_path=index_path
    )
    
    # –°–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    question = "–ö–∞–∫–æ–≤–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä–æ–º –∏ –í–æ–ª–¥–µ–º–æ—Ä—Ç–æ–º? –ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ –ì–∞—Ä—Ä–∏ –±—ã–ª –∏–∑–±—Ä–∞–Ω?"
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π RAG
    print("\n" + "="*50)
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ô")
    print("="*50)
    
    # Advanced RAG
    result = rag.advanced_query(
        question,
        k=4,
        use_multi_query=True,
        use_reranking=True
    )
    
    print("\n" + "="*50)
    print("üí° –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢:")
    print("="*50)
    print(result['answer'])
    print(f"\nüìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {result['num_docs_retrieved']}")
    print(f"üìñ –ö–Ω–∏–≥–∏: {', '.join(set(result['sources']))}")


if __name__ == "__main__":
    demo_advanced_rag()

