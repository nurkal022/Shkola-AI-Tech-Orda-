"""
RAG –®–∞–≥ 6: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç
============================
–ß–∞—Ç-–±–æ—Ç —Å –ø–∞–º—è—Ç—å—é –¥–∏–∞–ª–æ–≥–∞ –∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º.
"""
from pathlib import Path
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema.output_parser import StrOutputParser
from langchain.memory import ConversationBufferWindowMemory

load_dotenv()

# ============================================================
# –ù–ê–°–¢–†–û–ô–ö–ê
# ============================================================
INDEX_PATH = "./faiss_harry_potter"

if not Path(INDEX_PATH).exists():
    print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ 04_rag_pipeline.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞")
    exit()

# –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.7, streaming=True)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)

# –ü–∞–º—è—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π)
memory = ConversationBufferWindowMemory(k=10, return_messages=True)

# –ü—Ä–æ–º–ø—Ç
prompt = ChatPromptTemplate.from_messages([
    ("system", """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä—É. –û—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥: {context}"""),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])

print("‚úÖ –ß–∞—Ç-–±–æ—Ç –≥–æ—Ç–æ–≤!")


# ============================================================
# –§–£–ù–ö–¶–ò–Ø –ß–ê–¢–ê
# ============================================================
def chat(question: str):
    """–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –ø–∞–º—è—Ç—å—é –∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º"""
    
    # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    docs = vectorstore.similarity_search(question, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    
    # –ò—Å—Ç–æ—Ä–∏—è
    history = memory.load_memory_variables({})["history"]
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º
    chain = prompt | llm | StrOutputParser()
    
    print("ü§ñ ", end="", flush=True)
    response = ""
    for chunk in llm.stream(prompt.format_messages(
        context=context, 
        history=history, 
        question=question
    )):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            response += chunk.content
    print()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
    memory.save_context({"input": question}, {"output": response})
    
    return response


# ============================================================
# –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú
# ============================================================
if __name__ == "__main__":
    print("\n" + "="*60)
    print("üßô‚Äç‚ôÇÔ∏è HARRY POTTER CHATBOT")
    print("="*60)
    print("–ö–æ–º–∞–Ω–¥—ã: /clear - –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å, /quit - –≤—ã—Ö–æ–¥")
    print("="*60 + "\n")
    
    while True:
        try:
            question = input("üë§ –í—ã: ").strip()
            
            if not question:
                continue
            if question == "/quit":
                print("üëã –ü–æ–∫–∞!")
                break
            if question == "/clear":
                memory.clear()
                print("üóëÔ∏è –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
                continue
            
            chat(question)
            print()
            
        except KeyboardInterrupt:
            print("\nüëã –ü–æ–∫–∞!")
            break
