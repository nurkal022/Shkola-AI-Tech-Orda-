"""
–®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ Embeddings –∏ Vector Store
=========================================
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä—ã –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""

import os
from pathlib import Path
from typing import List, Optional
from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS, Chroma
from langchain.schema import Document

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class EmbeddingManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å embeddings"""
    
    def __init__(self, model: str = "text-embedding-3-small"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embedding –º–æ–¥–µ–ª–∏.
        
        Args:
            model: –ú–æ–¥–µ–ª—å –¥–ª—è embeddings
                - text-embedding-3-small (–¥–µ—à–µ–≤–ª–µ, –±—ã—Å—Ç—Ä–µ–µ)
                - text-embedding-3-large (—Ç–æ—á–Ω–µ–µ, –¥–æ—Ä–æ–∂–µ)
                - text-embedding-ada-002 (legacy)
        """
        self.embeddings = OpenAIEmbeddings(model=model)
        self.model_name = model
        print(f"‚úÖ Embedding –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {model}")
    
    def embed_query(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–∑–∞–ø—Ä–æ—Å–∞)"""
        return self.embeddings.embed_query(text)
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """–ü–æ–ª—É—á–∏—Ç—å embeddings –¥–ª—è —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        return self.embeddings.embed_documents(texts)


class VectorStoreManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏"""
    
    def __init__(self, embedding_manager: EmbeddingManager):
        self.embedding_manager = embedding_manager
        self.vectorstore = None
    
    def create_faiss_store(
        self, 
        documents: List[Document],
        save_path: Optional[str] = None
    ) -> FAISS:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ FAISS –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
        
        FAISS - –±—ã—Å—Ç—Ä—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
        –ü–ª—é—Å—ã: –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
        –ú–∏–Ω—É—Å—ã: –Ω–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        """
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        self.vectorstore = FAISS.from_documents(
            documents=documents,
            embedding=self.embedding_manager.embeddings
        )
        
        if save_path:
            self.save_faiss(save_path)
        
        print(f"‚úÖ FAISS –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω!")
        return self.vectorstore
    
    def save_faiss(self, path: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –¥–∏—Å–∫"""
        if self.vectorstore and isinstance(self.vectorstore, FAISS):
            self.vectorstore.save_local(path)
            print(f"üíæ FAISS –∏–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {path}")
    
    def load_faiss(self, path: str) -> FAISS:
        """–ó–∞–≥—Ä—É–∑–∫–∞ FAISS –∏–Ω–¥–µ–∫—Å–∞ —Å –¥–∏—Å–∫–∞"""
        self.vectorstore = FAISS.load_local(
            path, 
            self.embedding_manager.embeddings,
            allow_dangerous_deserialization=True
        )
        print(f"üìÇ FAISS –∏–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
        return self.vectorstore
    
    def create_chroma_store(
        self, 
        documents: List[Document],
        persist_directory: str = "./chroma_db"
    ) -> Chroma:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ Chroma –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
        
        Chroma - –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.
        –ü–ª—é—Å—ã: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
        –ú–∏–Ω—É—Å—ã: –º–µ–¥–ª–µ–Ω–Ω–µ–µ FAISS
        """
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ Chroma –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embedding_manager.embeddings,
            persist_directory=persist_directory
        )
        
        print(f"‚úÖ Chroma –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {persist_directory}")
        return self.vectorstore
    
    def similarity_search(
        self, 
        query: str, 
        k: int = 4
    ) -> List[Document]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        if not self.vectorstore:
            raise ValueError("Vectorstore –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        
        return self.vectorstore.similarity_search(query, k=k)
    
    def similarity_search_with_score(
        self, 
        query: str, 
        k: int = 4
    ) -> List[tuple]:
        """
        –ü–æ–∏—Å–∫ —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä—ã (–¥–æ–∫—É–º–µ–Ω—Ç, score).
        """
        if not self.vectorstore:
            raise ValueError("Vectorstore –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        
        return self.vectorstore.similarity_search_with_score(query, k=k)


def create_documents_from_books(data_dir: str = "data") -> List[Document]:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –∫–Ω–∏–≥ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.
    """
    from text_chunking import create_recursive_splitter, ChunkConfig
    
    documents = []
    data_path = Path(data_dir)
    
    config = ChunkConfig(chunk_size=1000, chunk_overlap=200)
    splitter = create_recursive_splitter(config)
    
    for file_path in sorted(data_path.glob("*.txt")):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        filename = file_path.stem
        book_num = 0
        if '#' in filename:
            try:
                book_num = int(filename.split('#')[1].split(']')[0])
            except:
                pass
        
        parts = filename.split(']_')
        title = parts[1].replace('_', ' ') if len(parts) > 1 else filename
        
        # –ß–∏—Ç–∞–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        chunks = splitter.split_text(text)
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        for i, chunk in enumerate(chunks):
            doc = Document(
                page_content=chunk,
                metadata={
                    "source": filename,
                    "book_number": book_num,
                    "title": title,
                    "chunk_id": i,
                    "total_chunks": len(chunks)
                }
            )
            documents.append(doc)
        
        print(f"üìñ {title}: {len(chunks)} —á–∞–Ω–∫–æ–≤")
    
    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    return documents


def demo_vectorstore():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º"""
    print("="*60)
    print("üóÑÔ∏è –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø VECTOR STORE")
    print("="*60)
    
    # –°–æ–∑–¥–∞–µ–º embedding manager
    embed_manager = EmbeddingManager(model="text-embedding-3-small")
    
    # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    documents = create_documents_from_books()
    
    # –°–æ–∑–¥–∞–µ–º vector store manager
    vs_manager = VectorStoreManager(embed_manager)
    
    # –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å
    vs_manager.create_faiss_store(documents, save_path="./faiss_index")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ö—Ç–æ —Ç–∞–∫–æ–π –í–æ–ª–¥–µ–º–æ—Ä—Ç?",
        "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –•–æ–≥–≤–∞—Ä—Ç—Å",
        "–ö–∞–∫ –ì–∞—Ä—Ä–∏ —É–∑–Ω–∞–ª —á—Ç–æ –æ–Ω –≤–æ–ª—à–µ–±–Ω–∏–∫?",
        "–ö—Ç–æ –¥—Ä—É–∑—å—è –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä–∞?"
    ]
    
    print("\n" + "="*60)
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–ê")
    print("="*60)
    
    for query in test_queries:
        print(f"\n‚ùì –ó–∞–ø—Ä–æ—Å: {query}")
        print("-"*40)
        
        results = vs_manager.similarity_search_with_score(query, k=2)
        
        for doc, score in results:
            print(f"üìÑ [{doc.metadata['title']}] (score: {score:.4f})")
            print(f"   {doc.page_content[:200]}...")
            print()


if __name__ == "__main__":
    demo_vectorstore()

