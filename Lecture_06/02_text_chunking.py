"""
–®–∞–≥ 2: –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ (Chunking)
==========================================
–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —ç—Ç–∞–ø –¥–ª—è RAG - –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞.
"""

from typing import List, Dict, Any
from dataclasses import dataclass
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    CharacterTextSplitter,
    TokenTextSplitter
)
from langchain.schema import Document


@dataclass
class ChunkConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è chunking"""
    chunk_size: int = 1000
    chunk_overlap: int = 200
    separators: List[str] = None
    
    def __post_init__(self):
        if self.separators is None:
            # –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            self.separators = ["\n\n", "\n", ". ", "! ", "? ", "; ", ", ", " "]


def create_recursive_splitter(config: ChunkConfig) -> RecursiveCharacterTextSplitter:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä - –ª—É—á—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤.
    –ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º, –∑–∞—Ç–µ–º –ø–æ –º–µ–ª–∫–∏–º.
    """
    return RecursiveCharacterTextSplitter(
        chunk_size=config.chunk_size,
        chunk_overlap=config.chunk_overlap,
        separators=config.separators,
        length_function=len,
    )


def create_character_splitter(config: ChunkConfig) -> CharacterTextSplitter:
    """
    –ü—Ä–æ—Å—Ç–æ–π —Å–ø–ª–∏—Ç—Ç–µ—Ä –ø–æ —Å–∏–º–≤–æ–ª–∞–º.
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é.
    """
    return CharacterTextSplitter(
        chunk_size=config.chunk_size,
        chunk_overlap=config.chunk_overlap,
        separator="\n\n",
    )


def chunk_text(text: str, splitter) -> List[str]:
    """–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏"""
    return splitter.split_text(text)


def chunk_with_metadata(
    text: str, 
    metadata: Dict[str, Any],
    splitter
) -> List[Document]:
    """
    –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
    –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ –ø–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ + –Ω–æ–º–µ—Ä —á–∞–Ω–∫–∞.
    """
    chunks = splitter.split_text(text)
    documents = []
    
    for i, chunk in enumerate(chunks):
        doc_metadata = metadata.copy()
        doc_metadata["chunk_id"] = i
        doc_metadata["chunk_total"] = len(chunks)
        
        documents.append(Document(
            page_content=chunk,
            metadata=doc_metadata
        ))
    
    return documents


def compare_chunking_strategies(text: str) -> Dict[str, List[str]]:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π chunking.
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
    """
    results = {}
    
    # –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
    sizes = [500, 1000, 1500, 2000]
    
    for size in sizes:
        config = ChunkConfig(chunk_size=size, chunk_overlap=size // 5)
        splitter = create_recursive_splitter(config)
        chunks = chunk_text(text, splitter)
        results[f"recursive_{size}"] = chunks
        
    return results


def analyze_chunks(chunks: List[str], name: str = "chunks") -> None:
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è"""
    if not chunks:
        print(f"‚ùå {name}: –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤")
        return
        
    lengths = [len(c) for c in chunks]
    
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ '{name}':")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
    print(f"   –ú–∏–Ω. —Ä–∞–∑–º–µ—Ä: {min(lengths):,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {max(lengths):,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {sum(lengths) // len(lengths):,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {sum(lengths):,} —Å–∏–º–≤–æ–ª–æ–≤")


def demo_chunking():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π chunking"""
    from pathlib import Path
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—É—é –∫–Ω–∏–≥—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    data_path = Path("data")
    first_book = list(data_path.glob("*.txt"))[0]
    
    with open(first_book, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print("="*60)
    print("üî™ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø CHUNKING –°–¢–†–ê–¢–ï–ì–ò–ô")
    print("="*60)
    print(f"üìñ –§–∞–π–ª: {first_book.name}")
    print(f"üìè –†–∞–∑–º–µ—Ä: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ú–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (–¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞)
    config_small = ChunkConfig(chunk_size=500, chunk_overlap=100)
    splitter_small = create_recursive_splitter(config_small)
    chunks_small = chunk_text(text, splitter_small)
    analyze_chunks(chunks_small, "–ú–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ (500)")
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –°—Ä–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏ (–±–∞–ª–∞–Ω—Å)
    config_medium = ChunkConfig(chunk_size=1000, chunk_overlap=200)
    splitter_medium = create_recursive_splitter(config_medium)
    chunks_medium = chunk_text(text, splitter_medium)
    analyze_chunks(chunks_medium, "–°—Ä–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏ (1000)")
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ë–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (–±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    config_large = ChunkConfig(chunk_size=2000, chunk_overlap=400)
    splitter_large = create_recursive_splitter(config_large)
    chunks_large = chunk_text(text, splitter_large)
    analyze_chunks(chunks_large, "–ë–æ–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (2000)")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞
    print("\n" + "="*60)
    print("üìù –ü–†–ò–ú–ï–† –ß–ê–ù–ö–ê (—Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä):")
    print("="*60)
    print(chunks_medium[10][:500] + "...")
    
    return chunks_medium


if __name__ == "__main__":
    demo_chunking()

