"""
–®–∞–≥ 4: RAG Pipeline - Retrieval-Augmented Generation
====================================================
–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4.1-mini –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
"""

import os
from pathlib import Path
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

load_dotenv()


class RAGPipeline:
    """
    RAG Pipeline –¥–ª—è –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã.
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    1. Query ‚Üí Embedding ‚Üí Vector Search
    2. Retrieved Documents + Query ‚Üí LLM
    3. LLM ‚Üí Answer
    """
    
    def __init__(
        self,
        model_name: str = "gpt-4.1-mini",
        embedding_model: str = "text-embedding-3-small",
        temperature: float = 0.3,
        vectorstore_path: Optional[str] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG pipeline.
        
        Args:
            model_name: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (gpt-4.1-mini, gpt-4o, gpt-4o-mini)
            embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è embeddings
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0 = –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ, 1 = –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ)
            vectorstore_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É
        """
        print(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Pipeline...")
        
        # LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=temperature
        )
        print(f"   ‚úÖ LLM: {model_name}")
        
        # Embeddings
        self.embeddings = OpenAIEmbeddings(model=embedding_model)
        print(f"   ‚úÖ Embeddings: {embedding_model}")
        
        # Vector store
        self.vectorstore = None
        if vectorstore_path and Path(vectorstore_path).exists():
            self.load_vectorstore(vectorstore_path)
        
        # –ü—Ä–æ–º–ø—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.prompt = self._create_default_prompt()
        
    def _create_default_prompt(self) -> ChatPromptTemplate:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è RAG"""
        template = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–Ω–∏–≥–∞–º –æ –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä–µ. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, 
–∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ - —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –¶–∏—Ç–∏—Ä—É–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–≥–¥–∞ —É–º–µ—Å—Ç–Ω–æ
4. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:"""
        
        return ChatPromptTemplate.from_template(template)
    
    def load_vectorstore(self, path: str) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        self.vectorstore = FAISS.load_local(
            path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        print(f"   ‚úÖ Vector store –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
    
    def create_vectorstore(
        self, 
        documents: List[Document],
        save_path: Optional[str] = None
    ) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ vector store –∏–∑ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        self.vectorstore = FAISS.from_documents(
            documents=documents,
            embedding=self.embeddings
        )
        
        if save_path:
            self.vectorstore.save_local(save_path)
            print(f"üíæ Vector store —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        
        print(f"‚úÖ Vector store —Å–æ–∑–¥–∞–Ω!")
    
    def retrieve(self, query: str, k: int = 4) -> List[Document]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        if not self.vectorstore:
            raise ValueError("Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        
        return self.vectorstore.similarity_search(query, k=k)
    
    def format_docs(self, docs: List[Document]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        formatted = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            formatted.append(f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {source}]\n{doc.page_content}")
        return "\n\n---\n\n".join(formatted)
    
    def query(
        self, 
        question: str, 
        k: int = 4,
        return_sources: bool = False
    ) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞.
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            return_sources: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        
        Returns:
            Dict —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        """
        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        docs = self.retrieve(question, k=k)
        
        # 2. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = self.format_docs(docs)
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        chain = self.prompt | self.llm | StrOutputParser()
        
        answer = chain.invoke({
            "context": context,
            "question": question
        })
        
        result = {"answer": answer}
        
        if return_sources:
            result["sources"] = [
                {
                    "title": doc.metadata.get('title'),
                    "book_number": doc.metadata.get('book_number'),
                    "content_preview": doc.page_content[:200] + "..."
                }
                for doc in docs
            ]
        
        return result
    
    def query_with_chain(self, question: str, k: int = 4) -> str:
        """
        –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LCEL chain.
        –ë–æ–ª–µ–µ —ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–π, –Ω–æ –º–µ–Ω–µ–µ –≥–∏–±–∫–∏–π.
        """
        if not self.vectorstore:
            raise ValueError("Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        
        retriever = self.vectorstore.as_retriever(search_kwargs={"k": k})
        
        chain = (
            {"context": retriever | self.format_docs, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
        
        return chain.invoke(question)


def create_documents_from_books(data_dir: str = "data") -> List[Document]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–Ω–∏–≥"""
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    
    documents = []
    data_path = Path(data_dir)
    
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", "! ", "? ", "; ", ", ", " "]
    )
    
    for file_path in sorted(data_path.glob("*.txt")):
        filename = file_path.stem
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        book_num = 0
        if '#' in filename:
            try:
                book_num = int(filename.split('#')[1].split(']')[0])
            except:
                pass
        
        parts = filename.split(']_')
        title = parts[1].replace('_', ' ') if len(parts) > 1 else filename
        
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        chunks = splitter.split_text(text)
        
        for i, chunk in enumerate(chunks):
            documents.append(Document(
                page_content=chunk,
                metadata={
                    "source": filename,
                    "book_number": book_num,
                    "title": title,
                    "chunk_id": i
                }
            ))
        
        print(f"üìñ {title}: {len(chunks)} —á–∞–Ω–∫–æ–≤")
    
    return documents


def demo_rag():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è RAG pipeline"""
    print("="*60)
    print("ü§ñ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG PIPELINE")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    index_path = "./faiss_harry_potter"
    
    if Path(index_path).exists():
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
        print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        rag = RAGPipeline(
            model_name="gpt-4.1-mini",
            vectorstore_path=index_path
        )
    else:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        print("\nüî® –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        rag = RAGPipeline(model_name="gpt-4.1-mini")
        
        documents = create_documents_from_books()
        rag.create_vectorstore(documents, save_path=index_path)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    questions = [
        "–ö—Ç–æ —Ç–∞–∫–æ–π –í–æ–ª–¥–µ–º–æ—Ä—Ç –∏ –ø–æ—á–µ–º—É –µ–≥–æ –±–æ—è—Ç—Å—è?",
        "–ö–∞–∫ –ì–∞—Ä—Ä–∏ –ø–æ–ø–∞–ª –≤ –•–æ–≥–≤–∞—Ä—Ç—Å?",
        "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –∫—Ä–µ—Å—Ç—Ä–∞–∂–∏",
        "–ö—Ç–æ —Ç–∞–∫–æ–π –°–µ–≤–µ—Ä—É—Å –°–Ω–µ–π–ø?",
    ]
    
    print("\n" + "="*60)
    print("üí¨ –î–ò–ê–õ–û–ì –° RAG –°–ò–°–¢–ï–ú–û–ô")
    print("="*60)
    
    for question in questions:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        print("-"*50)
        
        result = rag.query(question, k=4, return_sources=True)
        
        print(f"üí° –û—Ç–≤–µ—Ç:\n{result['answer']}")
        
        print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
        for source in result['sources']:
            print(f"   - {source['title']} (–∫–Ω–∏–≥–∞ #{source['book_number']})")
        
        print("\n" + "="*60)


if __name__ == "__main__":
    demo_rag()

